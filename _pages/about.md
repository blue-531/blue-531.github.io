---
permalink: /
title: "Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a 2nd year Ph.D. student advised by Prof. [Kuk-Jin Yoon](https://scholar.google.co.kr/citations?user=1NvBj_gAAAAJ&hl=en) at [Visual Intelligence Lab (VILab)](https://vi.kaist.ac.kr/), Korea Advanced Institute of Science and Technology (KAIST). 
I am actively seeking for a research intern position.
<br/>

I am currently pursuing research focused on advancing 3D perception for autonomous driving, with an emphasis on developing models that are generalizable and robust across various domains. I am also particularly interested in utilizing diverse data modalities such as LiDAR, cameras, and event cameras.
<br/>

My CV can be found [here.](https://blue-531.github.io/assets/Hyun_Kurl_Jang_Curriculum_Vitae241013.pdf)
<br/>




Publications
======
<div style="display: flex; align-items: center;">
    <img src='/images/qual_kitti.png' alt='NeurIPS 2024' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        <a href="https://paperswithcode.com/sota/3d-semantic-scene-completion-on-semantickitti?p=talos-enhancing-semantic-scene-completion-via">
            <img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/talos-enhancing-semantic-scene-completion-via/3d-semantic-scene-completion-on-semantickitti" alt="PWC">
        </a><br>
        TALoS: Enhancing Semantic Scene Completion via Test-time Adaptation on the Line of Sight<br>
        <b>H. Jang*</b>, J. Kim*, H. Kweon*, K. Yoon<br>
        <b>NeurIPS 2024</b><br>
        <a href="https://arxiv.org/pdf/2410.15674">[paper]</a> <a href="https://github.com/blue-531/TALoS">[code]</a>
        
    </div>
    <br/>

</div>
<br/>
<div style="display: flex; align-items: center;">
    <img src='/images/GMT.png' alt='ECCV 2024' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        GMT: Enhancing Generalizable Neural Rendering via Geometry-Driven Multi-Reference Texture Transfer<br>
        Y. Yoon*, <b>H. Jang*</b>, K. Yoon<br>
        <b>ECCV 2024</b><br>
        <a href="https://arxiv.org/pdf/2410.00672">[paper]</a>
    </div>
</div>
<br/>
<div style="display: flex; align-items: center;">
    <img src='/images/event-vfi.png' alt='CVPR 2023' class="publication-image">

    <!-- Text Content -->
    <div class="publication-info">
        Event-based Video Frame Interpolation with Cross-Modal Asymmetric Bidirectional Motion Fields<br>
        T. Kim, Y. Chae, <b>H. Jang</b>, K. Yoon<br>
        <b>CVPR 2023 (2.5% of submissions)</b><br>
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Event-Based_Video_Frame_Interpolation_With_Cross-Modal_Asymmetric_Bidirectional_Motion_Fields_CVPR_2023_paper.pdf">[paper]</a> <a href="https://github.com/intelpro/CBMNet">[code]</a>
    </div>
</div>
<br/>

<style>
    .publication-container {
        display: flex;
        align-items: center;
    }

    .publication-image {
        margin-right: 13px;
        width: 250px; /* Default width */
        height: 140px; /* Default height */
    }

    .publication-image-simulation {
        margin-right: 13px;
        width: 250px; /* Default width */
        height: 190px; /* Default height */
    }

    .publication-image-narrow {
        margin-right: 13px;
        width: 180px; /* Default width */
        height: 240px; /* Default height */
    }

    .publication-image-middle {
        margin-right: 13px;
        width: 205px; /* Default width */
        height: 185px; /* Default height */
    }

    .publication-info {
        flex-grow: 1; /* Allow text to expand */
    }

    /* Media query for smaller screens (e.g., mobile devices) */
    @media (max-width: 1000px) {
        .publication-image {
            width: 150px; /* Adjusted width for smaller screens */
            height: 84px; /* Adjusted height for smaller screens */
        }
    }

    @media (max-width: 1000px) {
        .publication-image-simulation {
            width: 150px; /* Adjusted width for smaller screens */
            height: 120px; /* Adjusted height for smaller screens */
        }
    }
    
    @media (max-width: 1000px) {
        .publication-image-narrow {
            width: 100px; /* Adjusted width for smaller screens */
            height: 133px; /* Adjusted height for smaller screens */
        }
    }

    @media (max-width: 1000px) {
        .publication-image-middle {
            width: 110px; /* Adjusted width for smaller screens */
            height: 100px; /* Adjusted height for smaller screens */
        }
    }
    
</style>


Selected Honors and Awards
======
- 2023 / Gold prize in Best Paper Awards during IPIU 2023, 35th Workshop on Image Processing and Image Understanding
<br/>


Projects
======
- 2022 ~ 2024 / AI Research for Intelligent X-ray Luggage Scanning System / X-ray imaging, object detection, weakly supervised object localization
<br/>


